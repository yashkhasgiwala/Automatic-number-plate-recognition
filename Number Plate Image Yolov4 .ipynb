{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = open('obj.names.txt').read().strip().split('\\n')#reading pretrained object labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 'yolov4-obj_last.weights'#pretrained weights\n",
    "architecture = 'yolov4-obj.cfg.txt'#Neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.dnn.readNet(architecture,weights)#reading the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('car.jpg')#reading static image\n",
    "Height,Width = image.shape[:2]#for scaling our bounding box wrt to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 608, 608)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = cv2.dnn.blobFromImage(image, 1/255.0, (608, 608), swapRB=True, crop=False)\n",
    "blob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setInput(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(model):\n",
    "    layers = model.getLayerNames()#get all layer names\n",
    "    output_layer = [layers[i[0]-1] for i in model.getUnconnectedOutLayers()]#get names of output layers\n",
    "    return model.forward(output_layer)#does forward prop and gives output for the layers passed to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE = 0.5\n",
    "IOU_THRESHOLD = 0.5\n",
    "boxes, confidences, class_ids = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = forward_prop(model)#outputs of the last layer of NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in outputs:#loop through output of NN\n",
    "    for pred in output:#loop through all predictions\n",
    "        class_scores = pred[5:]#get class probs\n",
    "        class_id = np.argmax(class_scores)#find max class prob\n",
    "        class_prob = class_scores[class_id]#get class_id of class with max prob\n",
    "        if class_prob>CONFIDENCE:\n",
    "            #scale dimensions of bounding box wrt to image\n",
    "            center_x = int(pred[0] * Width)\n",
    "            center_y = int(pred[1] * Height)\n",
    "            w = int(pred[2] * Width)\n",
    "            h = int(pred[3] * Height)\n",
    "            #getting top-left co-ordinates\n",
    "            x = center_x - (w / 2)\n",
    "            y = center_y - (h / 2)\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(class_prob))\n",
    "            boxes.append([x, y, w, h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=cv2.dnn.NMSBoxes(boxes,confidences,CONFIDENCE,IOU_THRESHOLD)#performs nms and returns boxes to be kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(image,x,y,w,h,class_id,prob):\n",
    "    label = labels[class_id]#getting label\n",
    "    text = label+' : '+str(prob)\n",
    "    cv2.rectangle(image,(x+2,y),(x+w-2,y+h),color=(255,0,0),thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices.flatten():\n",
    "    x,y,w,h = boxes[i][0],boxes[i][1],boxes[i][2],boxes[i][3]\n",
    "    prob=round(confidences[i], 3)\n",
    "    bounding_box(image,int(x),int(y),int(w),int(h), class_ids[i] ,prob )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606.5 450.0 835.5 500.0\n"
     ]
    }
   ],
   "source": [
    "print(x,y,x+w,y+h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"object detection\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"plate_1.jpg\",image[int(y)+2:int(y)+int(h)-2,int(x)+2:int(x)+int(w)-2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
